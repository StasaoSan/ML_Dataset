{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset.\n",
    "Сайт: https://www.allrecipes.com, раздел everyday-cooking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3625a0b853a2407b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Парсинг. Main. Задание начальных параметров и запуск\n",
    "\n",
    "Выделены следующие признаки для объекта, проходящего парсинг:\n",
    "- URL - ссылка - (str) \n",
    "- Title - название - (str) \n",
    "- Caterory - категория (str) (В последствии этот признак выбран целевым)\n",
    "- Rating - рейтинг - (float)\n",
    "- Preparation time - время подготовки - (int)\n",
    "- Cook time - время приготовления - (int)\n",
    "- Total time - общее время - (int)\n",
    "- Servings - число порций - (int)\n",
    "- Ingredientrs - ингредиенты - (str)\n",
    "- Image - изображения - (str) (в таблице сохраняются пути для скачанных изображений) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8718e8e46289b1d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import arff\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from parse_site import start_parse\n",
    "from difflib import SequenceMatcher\n",
    "from binarize_data import binarize_data\n",
    "from arff_helper import write_arff, read_tsv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from unificate_funcs import time_to_minutes, unificate_ingredients, process_servings\n",
    "\n",
    "tsv_filename = 'allrecipes_everyday_cooking.tsv'\n",
    "arff_filename = 'allrecipes_everyday_cooking.arff'\n",
    "output_csv = 'allrecipes_binarized_everyday_cooking.csv'\n",
    "filter_keyword = 'everyday-cooking'\n",
    "\n",
    "start_parse(tsv_filename, arff_filename, output_csv, filter_keyword)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bd744cd7e318a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Основная функция управляющая всем парсингом и последующими действиями."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e05c9fbd9e1024"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def start_parse(tsv_filename, arff_filename, output_csv, filter_keyword=None):\n",
    "    category_links = get_category_links(filter_keyword)\n",
    "    all_recipes = []\n",
    "    for category_url in category_links:\n",
    "        print(f\"Парсинг категории: {category_url}\")\n",
    "        category_recipes = get_recipes_from_category_or_list(category_url)\n",
    "        all_recipes.extend(category_recipes)\n",
    "        print(f\"Собрано {len(category_recipes)} рецептов из категории {category_url}\")\n",
    "\n",
    "    print(f\"Всего рецептов собрано: {len(all_recipes)}\")\n",
    "\n",
    "    df = pd.DataFrame(all_recipes,\n",
    "                      columns=['URL', 'Title', 'Category', 'Rating', 'Prep_Time_(min)',\n",
    "                               'Cook_Time_(min)', 'Total_Time_(min)', 'Servings',\n",
    "                               'Ingredients', 'Image_Paths'])\n",
    "    df.to_csv(tsv_filename, sep='\\t', index=False)\n",
    "\n",
    "    df = read_tsv(tsv_filename)\n",
    "    write_arff(df, arff_filename)\n",
    "\n",
    "    binarize_data(arff_filename, output_csv)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12bb53e6a3b65782"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Изначальной задачей было найти необходимый раздел. Ищем header на главной странице сайта, далее ищем все возможные ссылки содержащие в себе 'everyday-cooking'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdf6cbc7a049cd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T16:15:36.338961Z",
     "start_time": "2024-10-15T16:15:36.327647Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_category_links(filter_keyword=None):\n",
    "    url = \"https://www.allrecipes.com/\"\n",
    "    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    nav = soup.find('nav', id='mntl-header-nav_1-0')\n",
    "    categories = nav.find_all('a', href=True)\n",
    "    category_links = [category['href'] for category in categories if 'recipes' in category['href']]\n",
    "    if filter_keyword:\n",
    "        category_links = [link for link in category_links if filter_keyword in link]\n",
    "    return category_links"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее, так как структура рецептов может быть вложенной - необходимо описать взаимодействие с парсингом страниц, имеющих сами рецепты, а так же вложенные ссылки на рецепты. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad184e36e35e7b28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_recipes_from_nested_list(soup):\n",
    "    nested_recipes = []\n",
    "    recipe_list = soup.find('div', class_='comp list-sc mntl-block article-content list')\n",
    "    if recipe_list:\n",
    "        content_list = recipe_list.find('div', class_='comp list-sc__content mntl-sc-page mntl-block')\n",
    "        if content_list:\n",
    "            list_items = content_list.find_all('div', class_='comp list-sc-item mntl-block mntl-sc-list-item')\n",
    "            for item in list_items:\n",
    "                title_block = item.find('span', class_='mntl-sc-block-heading__text')\n",
    "                link_block = item.find('div',\n",
    "                                       class_='comp mntl-sc-block allrecipes-sc-block-featuredlink mntl-sc-block-universal-featured-link mntl-sc-block-universal-featured-link--button')\n",
    "\n",
    "                if title_block and link_block and link_block.find('a', href=True):\n",
    "                    recipe_title = title_block.text.strip()\n",
    "                    recipe_link = link_block.find('a', href=True)['href']\n",
    "\n",
    "                    if 'undefinedundefined' in recipe_link:\n",
    "                        print(f\"Пропуск рецепта с недействительной ссылкой: {recipe_title}\")\n",
    "                        continue\n",
    "\n",
    "                    print(f\"Парсинг вложенного рецепта: {recipe_title}, ссылка: {recipe_link}\")\n",
    "                    recipe_details = get_recipe_details(recipe_link, recipe_title)\n",
    "                    nested_recipes.extend(recipe_details)\n",
    "                else:\n",
    "                    print(f\"Пропуск элемента без заголовка или ссылки.\")\n",
    "\n",
    "        else:\n",
    "            print(\"Список контента не найден в рецепте.\")\n",
    "    else:\n",
    "        print(\"Рецепт не содержит вложенных элементов.\")\n",
    "\n",
    "    return nested_recipes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c78b3c1bb186c84"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_recipes_from_category_or_list(category_url):\n",
    "    recipes_data = []\n",
    "    response = requests.get(category_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    list_items = soup.find_all('div', class_='mntl-sc-block allrecipes-sc-block-heading mntl-sc-block-heading')\n",
    "\n",
    "    if list_items:\n",
    "        for list_item in list_items:\n",
    "            recipe_title = list_item.find('span', class_='mntl-sc-block-heading__text').text.strip()\n",
    "            recipe_link = list_item.find_next('a', href=True)['href']\n",
    "\n",
    "            if 'undefinedundefined' in recipe_link:\n",
    "                print(f\"Пропуск рецепта с недействительной ссылкой: {recipe_title}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Список рецептов: Переход к рецепту {recipe_title}\")\n",
    "            recipe_details = get_recipe_details(recipe_link, recipe_title)\n",
    "            recipes_data.extend(recipe_details)\n",
    "    else:\n",
    "        recipe_cards = soup.find_all('a', class_='mntl-card-list-items', href=True)\n",
    "        for card in recipe_cards:\n",
    "            recipe_url = card['href']\n",
    "\n",
    "            if 'undefinedundefined' in recipe_url:\n",
    "                print(f\"Пропуск рецепта с недействительной ссылкой: {recipe_url}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Парсинг рецепта: {recipe_url}\")\n",
    "            recipe_details = get_recipe_details(recipe_url)\n",
    "            recipes_data.extend(recipe_details)\n",
    "\n",
    "    return recipes_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44f78851d79c6994"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Приведенные выше функции используют get_recipe_detales для парсинга с уже найденной страницы рецепта необходимых признаков и их значений"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0d7dfc73cc32697"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_recipe_details(recipe_url, recipe_title=\"No title\"):\n",
    "    if 'undefinedundefined' in recipe_url:\n",
    "        print(f\"Пропуск недействительной ссылки: {recipe_url}\")\n",
    "        return []\n",
    "\n",
    "    response = requests.get(recipe_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    title = recipe_title if recipe_title != \"No title\" else (\n",
    "        soup.find('h1', class_='article-heading').text.strip() if soup.find('h1',\n",
    "                                                                            class_='article-heading') else 'No title')\n",
    "\n",
    "    if \"gallery\" in recipe_url or soup.find('div', class_='comp list-sc'):\n",
    "        print(f\"Найдено вложенное меню рецептов. Парсинг вложенных рецептов.\")\n",
    "        return get_recipes_from_nested_list(soup)\n",
    "\n",
    "    category = get_category_from_path(soup)\n",
    "\n",
    "    rating = np.nan\n",
    "    rating_block = soup.find('div', id='mm-recipes-review-bar_1-0')\n",
    "    if rating_block:\n",
    "        rating_value_block = rating_block.find('div', class_='mm-recipes-review-bar__rating')\n",
    "        if rating_value_block:\n",
    "            rating = rating_value_block.text.strip()\n",
    "\n",
    "    prep_time = cook_time = total_time = servings = np.nan\n",
    "    details_section = soup.find('div', class_='mm-recipes-details__content')\n",
    "    if details_section:\n",
    "        details_items = details_section.find_all('div', class_='mm-recipes-details__item')\n",
    "        for item in details_items:\n",
    "            label = item.find('div', class_='mm-recipes-details__label').text.strip()\n",
    "            value = item.find('div', class_='mm-recipes-details__value').text.strip()\n",
    "            if label == 'Prep Time:':\n",
    "                prep_time = time_to_minutes(value)\n",
    "            elif label == 'Cook Time:':\n",
    "                cook_time = time_to_minutes(value)\n",
    "            elif label == 'Total Time:':\n",
    "                total_time = time_to_minutes(value)\n",
    "            elif label == 'Servings:':\n",
    "                servings = process_servings(value)\n",
    "\n",
    "    ingredients = unificate_ingredients(parse_ingredients(soup))\n",
    "    image_paths = save_recipe_images(soup, title)\n",
    "    return [[recipe_url, title, category, rating, prep_time, cook_time, total_time,servings, ingredients, ', '.join(image_paths)]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cf60a94061b83ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так же функция для правильного парсинга ингредиентов:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b76434d1d1ed146"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_ingredients(soup):\n",
    "    ingredients = []\n",
    "    ingredients_div = soup.find('div', id='mm-recipes-structured-ingredients_1-0')\n",
    "\n",
    "    if ingredients_div:\n",
    "        ingredients_list = ingredients_div.find_all('li', class_='mm-recipes-structured-ingredients__list-item')\n",
    "        for item in ingredients_list:\n",
    "            quantity = item.find('span', attrs={'data-ingredient-quantity': 'true'})\n",
    "            unit = item.find('span', attrs={'data-ingredient-unit': 'true'})\n",
    "            name = item.find('span', attrs={'data-ingredient-name': 'true'})\n",
    "\n",
    "            ingredient_text = \"\"\n",
    "            if quantity:\n",
    "                ingredient_text += quantity.text.strip() + \" \"\n",
    "            if unit:\n",
    "                ingredient_text += unit.text.strip() + \" \"\n",
    "            if name:\n",
    "                ingredient_text += name.text.strip()\n",
    "\n",
    "            if ingredient_text.strip():\n",
    "                ingredients.append(ingredient_text.strip())\n",
    "\n",
    "    return ', '.join(ingredients) if ingredients else np.nan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d66e4e4cd6848104"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция сохранения изображений (изображения сохраняются в папке pics/\"name recipe\"/img_\"img num\".jpg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28ae92efa2153e10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_recipe_images(soup, recipe_name):\n",
    "    image_folder = os.path.join('pics', recipe_name)\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    article_content = soup.find('div', class_='loc article-content')\n",
    "\n",
    "    if not article_content:\n",
    "        print(\"Блок с контентом рецепта не найден.\")\n",
    "        return []\n",
    "\n",
    "    image_elements = article_content.find_all('img')\n",
    "    image_paths = []\n",
    "    image_count = 0\n",
    "\n",
    "    for img in image_elements:\n",
    "        img_url = img.get('src')\n",
    "\n",
    "        if not img_url:\n",
    "            continue\n",
    "\n",
    "        if 'srcset' in img.attrs:\n",
    "            img_url = img['srcset'].split(',')[-1].split()[0]\n",
    "\n",
    "        img_url = urljoin('https://www.allrecipes.com', img_url)\n",
    "        img_data = requests.get(img_url).content\n",
    "        img_name = f\"image_{image_count + 1}.jpg\"\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "\n",
    "        with open(img_path, 'wb') as img_file:\n",
    "            img_file.write(img_data)\n",
    "\n",
    "        image_paths.append(img_path)\n",
    "        image_count += 1\n",
    "\n",
    "    if image_count == 0:\n",
    "        print(\"Изображения не найдены для рецепта.\")\n",
    "    else:\n",
    "        print(f\"Всего сохранено изображений: {image_count} для рецепта {recipe_name}\")\n",
    "\n",
    "    return image_paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b6e5d169b1454b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция, используемая для парсинга категории из \"пути\" рецепта"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca8e0306d236ef40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_category_from_path(soup):\n",
    "    category = \"No info\"\n",
    "    breadcrumbs = soup.find('ul', class_='comp mntl-universal-breadcrumbs mntl-block type--squirrel breadcrumbs')\n",
    "    if breadcrumbs:\n",
    "        breadcrumb_items = breadcrumbs.find_all('li', class_='comp mntl-breadcrumbs__item mntl-block')\n",
    "\n",
    "        if len(breadcrumb_items) > 1:\n",
    "            category_span = breadcrumb_items[1].find('span', class_='link__wrapper')\n",
    "            if category_span:\n",
    "                category = category_span.text.strip()\n",
    "\n",
    "    return category"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95442a0355d8a88c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Однако полученные при парсинге данные требуют некоторой унификации, поэтому используются:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0ceac68d4cfbe08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Унификация времени (перевод едениц измерения в минуты)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c4209d0c2de93a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def time_to_minutes(time):\n",
    "    hours = 0\n",
    "    minutes = 0\n",
    "\n",
    "    hours_match = re.search(r'(\\d+)\\s*hr', time)\n",
    "    if hours_match:\n",
    "        hours = int(hours_match.group(1))\n",
    "\n",
    "    minutes_match = re.search(r'(\\d+)\\s*min', time)\n",
    "    if minutes_match:\n",
    "        minutes = int(minutes_match.group(1))\n",
    "\n",
    "    total_minutes = hours * 60 + minutes\n",
    "    return total_minutes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4e6b168473b4ea9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Унификация количества числа порций сервировки"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d3add90c52d3cfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_servings(servings_value):\n",
    "    if isinstance(servings_value, str) and 'to' in servings_value:\n",
    "        parts = servings_value.split('to')\n",
    "        try:\n",
    "            return str((float(parts[0].strip()) + float(parts[1].strip())) / 2)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    if isinstance(servings_value, str):\n",
    "        try:\n",
    "            return str(float(servings_value.split()[0]))\n",
    "        except (ValueError, IndexError):\n",
    "            return np.nan\n",
    "\n",
    "    return servings_value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebfa35b88147112a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Унификация объемов и масс ингредиентов"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a02a7b85726711"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unificate_ingredients(ingredients_string):\n",
    "    if not isinstance(ingredients_string, str):\n",
    "        return \"\"\n",
    "    ingredients = ingredients_string.split(', ')\n",
    "    ingredients_unificated = [unificate_ingr(ingr) for ingr in ingredients]\n",
    "\n",
    "    return ', '.join(ingredients_unificated)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acbae09bfc4b60bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unificate_ingr(ingredient):\n",
    "    ingredient = handle_fractional_numbers(ingredient)\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)\\s*([a-zA-Z]+)', ingredient)\n",
    "\n",
    "    if match:\n",
    "        quantity = float(match.group(1))\n",
    "        unit = match.group(3)\n",
    "        converted_quantity, conversion_factor = convert_to_base_unit(quantity, unit)\n",
    "        if conversion_factor:\n",
    "            normalized_str = re.sub(r'(\\d+(\\.\\d+)?)\\s*([a-zA-Z]+)', f'{converted_quantity:.2f} grams', ingredient)\n",
    "            return normalized_str\n",
    "\n",
    "    return ingredient"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bdf081d85a16816"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def handle_fractional_numbers(ingredient):\n",
    "    for frac, dec in fraction_conversion.items():\n",
    "        ingredient = ingredient.replace(frac, str(dec))\n",
    "\n",
    "    ingredient = re.sub(r'(\\d+)\\s+(\\d+\\.\\d+)', lambda match: str(float(match.group(1)) + float(match.group(2))), ingredient)\n",
    "\n",
    "    return ingredient"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be2a942e74f47f40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_to_base_unit(quantity, unit):\n",
    "    unit = unit.lower()\n",
    "    if unit in unit_conversion:\n",
    "        return quantity * unit_conversion[unit], unit_conversion[unit]\n",
    "    return quantity, None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9e0127de3523d2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Единицы измерения и их эквиваленты в граммах и миллилитрах\n",
    "\n",
    "Для удобства парсинга рецептов был использован следующий словарь для преобразования единиц измерения в граммы и миллилитры:\n",
    "\n",
    "- ounce = 28.35 грамм\n",
    "- pound = 453.6 грамм\n",
    "- cup = 240 мл\n",
    "- tablespoon = 15 мл\n",
    "- teaspoon = 5 мл\n",
    "- quart = 946 мл\n",
    "- liter = 1000 мл\n",
    "- clove = 5 грамм\n",
    "\n",
    "\n",
    "Этот словарь позволяет автоматически унифицировать различные единицы измерения в рецептах, такие как вес или объем ингредиентов. Полный список можно видеть ниже"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71b4bb4b045204c9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ounce': 28.35,\n 'ounces': 28.35,\n 'pound': 453.6,\n 'pounds': 453.6,\n 'cup': 240,\n 'cups': 240,\n 'tablespoon': 15,\n 'tablespoons': 15,\n 'teaspoon': 5,\n 'teaspoons': 5,\n 'quart': 946,\n 'quarts': 946,\n 'liter': 1000,\n 'liters': 1000,\n 'milliliter': 1,\n 'milliliters': 1,\n 'gram': 1,\n 'grams': 1,\n 'pinch': 0.36,\n 'pinches': 0.36,\n 'clove': 5,\n 'cloves': 5,\n 'slice': 15,\n 'slices': 15,\n 'piece': 20,\n 'pieces': 20,\n 'can': 400,\n 'cans': 400,\n 'dash': 0.6,\n 'dashes': 0.6,\n 'fluid ounce': 29.57,\n 'fluid ounces': 29.57,\n 'head': 400,\n 'heads': 400,\n 'sheet': 5,\n 'sheets': 5,\n 'wrapper': 10,\n 'wrappers': 10,\n 'egg': 50,\n 'eggs': 50,\n 'stick': 113,\n 'sticks': 113,\n 'package': 200,\n 'packages': 200,\n 'bunch': 100,\n 'bunches': 100,\n 'leaf': 5,\n 'leaves': 5,\n 'sprig': 2,\n 'sprigs': 2}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from conversation_dict import unit_conversion\n",
    "unit_conversion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T18:51:35.634078Z",
     "start_time": "2024-10-15T18:51:35.622634Z"
    }
   },
   "id": "aafdde2621a892fe"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'½': 0.5,\n '⅓': 0.3333333333333333,\n '¼': 0.25,\n '¾': 0.75,\n '⅔': 0.6666666666666666,\n '⅛': 0.125}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from conversation_dict import fraction_conversion\n",
    "fraction_conversion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T18:51:38.329692Z",
     "start_time": "2024-10-15T18:51:38.323378Z"
    }
   },
   "id": "60d5c4239756ac0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дальнейшей задачей было преобразование tsv в arff файл, чтение tsv происходит при помощи функции read_tsv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38e577dc103cb11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_tsv(tsv_filename):\n",
    "    return pd.read_csv(tsv_filename, sep='\\t')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35422e1a926a29e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее при помощи write_arff из открытого файла происходит запись в arff файл: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71d6c3442e122f63"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_arff(df, arff_filename):\n",
    "    if os.path.exists(arff_filename):\n",
    "        print(f\"ARFF файл '{arff_filename}' уже существует.\")\n",
    "        return\n",
    "\n",
    "    with open(arff_filename, 'w') as f:\n",
    "        f.write('@relation allrecipes_recipes\\n\\n')\n",
    "\n",
    "        f.write('@attribute URL string\\n')\n",
    "        f.write('@attribute Title string\\n')\n",
    "        f.write('@attribute Category string\\n')\n",
    "        f.write('@attribute Rating numeric\\n')\n",
    "        f.write('@attribute \"Prep_Time_(min)\" numeric\\n')\n",
    "        f.write('@attribute \"Cook_Time_(min)\" numeric\\n')\n",
    "        f.write('@attribute \"Total_Time_(min)\" numeric\\n')\n",
    "        f.write('@attribute Servings numeric\\n')\n",
    "        f.write('@attribute Ingredients string\\n')\n",
    "        f.write('@attribute \"Image_Paths\" string\\n\\n')\n",
    "\n",
    "        f.write('@data\\n')\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(f'\"{escape_quotes(row[\"URL\"])}\", \"{escape_quotes(row[\"Title\"])}\", '\n",
    "                    f'\"{escape_quotes(row[\"Category\"])}\", '\n",
    "                    f'{row[\"Rating\"] if pd.notnull(row[\"Rating\"]) else \"?\"}, '\n",
    "                    f'{row[\"Prep_Time_(min)\"] if pd.notnull(row[\"Prep_Time_(min)\"]) else \"?\"}, '\n",
    "                    f'{row[\"Cook_Time_(min)\"] if pd.notnull(row[\"Cook_Time_(min)\"]) else \"?\"}, '\n",
    "                    f'{row[\"Total_Time_(min)\"] if pd.notnull(row[\"Total_Time_(min)\"]) else \"?\"}, '\n",
    "                    f'{row[\"Servings\"] if pd.notnull(row[\"Servings\"]) else \"?\"}, '\n",
    "                    f'\"{escape_quotes(row[\"Ingredients\"])}\", \"{escape_quotes(row[\"Image_Paths\"])}\"\\n')\n",
    "\n",
    "    print(f\"ARFF файл '{arff_filename}' успешно создан.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84a15bf38906dfdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В функции write_arff используется escape_quotes для избегания ошибок связанных с тем, что в названиях могут быть кавычки, что приведет к неправильной интерпретации "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53e1fe3accd4dac4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def escape_quotes(s):\n",
    "    if isinstance(s, str):\n",
    "        return s.replace('\"', '\\\\\"')\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f32326409e190041"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Предобработка\n",
    "Целевым признаком выбран Category. Признаки URL, Title и Image_Paths исключены из итогового файла. Принято решение преобразовать признак Ingredients посредством one hot encoding. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84cc55950d224511"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def binarize_data(arff_filename, output_csv):\n",
    "    with open(arff_filename, 'r') as f:\n",
    "        dataset = arff.load(f)\n",
    "\n",
    "    df = pd.DataFrame(dataset['data'], columns=[attr[0] for attr in dataset['attributes']])\n",
    "\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        if isinstance(df[col].iloc[0], bytes):\n",
    "            df[col] = df[col].astype(str)\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    numeric_columns = df.select_dtypes(include=[float, int]).columns\n",
    "    df[numeric_columns] = df[numeric_columns].round(1)\n",
    "\n",
    "    if 'Ingredients' in df.columns:\n",
    "        df['Ingredients'] = df['Ingredients'].apply(lambda x: simplify_ingredients(x.split(',')) if pd.notna(x) else [])\n",
    "\n",
    "        unique_ingredients = set([ingredient for sublist in df['Ingredients'] for ingredient in sublist])\n",
    "        similar_ingredients_map = find_similar_ingredients(list(unique_ingredients))\n",
    "\n",
    "        df['Ingredients'] = df['Ingredients'].apply(lambda x: merge_similar_ingredients(x, similar_ingredients_map))\n",
    "\n",
    "        ingredients_df = df['Ingredients'].str.join('|').str.get_dummies()\n",
    "        ingredients_df = group_rare_ingredients(ingredients_df)\n",
    "\n",
    "        df = pd.concat([df, ingredients_df], axis=1)\n",
    "        df = df.drop('Ingredients', axis=1)\n",
    "\n",
    "    df = df.drop(['URL', 'Title', 'Image_Paths'], axis=1)\n",
    "\n",
    "    columns_to_normalize = ['Rating', 'Prep_Time_(min)', 'Cook_Time_(min)', 'Total_Time_(min)', 'Servings']\n",
    "    df = normalize_columns(df, columns_to_normalize)\n",
    "\n",
    "    if 'Category' in df.columns:\n",
    "        df['Category'] = df['Category']\n",
    "\n",
    "    if 'Title' in df.columns:\n",
    "        df['Title'] = df['Title']\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Бинаризация завершена. Данные сохранены в {output_csv}. Количество признаков: {len(df.columns)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "845db63387939dd4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В процессе преобразования использовались:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "208ec0bda9031ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize_columns(df, columns):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[columns] = scaler.fit_transform(df[columns])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5e96cf2241e3215"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_similar_ingredients(ingredient_list, similar_map):\n",
    "    return [similar_map.get(ingredient, ingredient) for ingredient in ingredient_list]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9b2eb1796d89d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def group_rare_ingredients(ingredients_df, min_frequency=5):\n",
    "    ingredient_counts = ingredients_df.sum(axis=0)\n",
    "    rare_ingredients = ingredient_counts[ingredient_counts < min_frequency].index\n",
    "\n",
    "    ingredients_df['other_ingredients'] = ingredients_df[rare_ingredients].sum(axis=1)\n",
    "    ingredients_df = ingredients_df.drop(columns=rare_ingredients)\n",
    "\n",
    "    return ingredients_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5d4a9e3e9bd3d3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "А так же для уменьшения числа признаков было принято решение объединить похожие посредством метрики Левенштейна:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adca9c53471dfc6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simplify_ingredients(ingredients):\n",
    "    simplified_ingredients = []\n",
    "\n",
    "    for ingredient in ingredients:\n",
    "        simplified = re.sub(r'\\d+\\s*\\w*', '', ingredient).strip()\n",
    "        simplified = re.sub(r'[().\\/®%-]', '', simplified).strip()\n",
    "        simplified_ingredients.append(simplified)\n",
    "    return simplified_ingredients"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7e822c55cb0fbfa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_similar_ingredients(ingredients, threshold=0.75):\n",
    "    similar_map = {}\n",
    "    for i in range(len(ingredients)):\n",
    "        for j in range(i + 1, len(ingredients)):\n",
    "            if SequenceMatcher(None, ingredients[i], ingredients[j]).ratio() > threshold:\n",
    "                if len(ingredients[i]) < len(ingredients[j]):\n",
    "                    similar_map[ingredients[j]] = ingredients[i]\n",
    "                else:\n",
    "                    similar_map[ingredients[i]] = ingredients[j]\n",
    "    return similar_map"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deb0db9012415117"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def merge_similar_ingredients(ingredient_list, similar_map):\n",
    "    merged_ingredients = []\n",
    "    for ingredient in ingredient_list:\n",
    "        merged_ingredients.append(similar_map.get(ingredient, ingredient))\n",
    "    return merged_ingredients"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89f7169102574a46"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
